{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rsjxD52SF0y3"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os \n",
        "from os import listdir\n",
        "from random import sample\n",
        "import pandas as pd\n",
        "import random\n",
        "np.random.seed(2)\n",
        "np.random.RandomState(2)\n",
        "import sklearn\n",
        "import cv2\n",
        "from skimage.filters import threshold_otsu\n",
        "from sklearn.utils import resample\n",
        "from google.colab.patches import cv2_imshow"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# A Note on File Paths"
      ],
      "metadata": {
        "id": "X04NMBwqd99G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The below code was written in Google Colab due to the time required to model the data. This notebook was mounted on the Google Drive, on the code file paths reflect as such. \n",
        "\n",
        "Similarly named files, i.e. the original images saved down in a file called 'raw_dataset' should result in the code running without issues.\n",
        "\n",
        "If any guidance is required, users are encouraged to reach out via Github."
      ],
      "metadata": {
        "id": "iu2TwHJkeAWv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CEIqaWqZI-dy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d42dac45-1d34-44bc-bc88-231674276aa0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Set up path to image dataset, create list of file names."
      ],
      "metadata": {
        "id": "kHRxeUc8Jf92"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yCns0nKKJKhU"
      },
      "outputs": [],
      "source": [
        "data_path = '/content/drive/MyDrive/clothing_class/raw_dataset'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_files = os.listdir(data_path)"
      ],
      "metadata": {
        "id": "090IC680tda3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Write Image Folder to CSV"
      ],
      "metadata": {
        "id": "gQ0ngyafP4xM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The image name and path are now written to a CSV that is saved in the file.\n",
        "\n",
        "Code guidance received from:\n",
        "\n",
        "https://gist.github.com/GermanCM/03754e11ac7e9a6343754ff389eb47f0\n",
        "\n",
        "https://stackoverflow.com/questions/58625312/printing-file-name-and-file-path-to-a-csv"
      ],
      "metadata": {
        "id": "OwhNrCjQFBt9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/drive/MyDrive/clothing_class/dataset.csv', 'w') as nf:\n",
        "    nf.write('file_name,file_path\\n')\n",
        "    for root, dirs, files in os.walk(data_path):\n",
        "        for x in files:\n",
        "            file_path= os.path.join(root, x)\n",
        "            file_name= os.path.basename(x)\n",
        "            nf.write('{},{}\\n'.format(file_name,file_path))"
      ],
      "metadata": {
        "id": "JW943O9KIEdf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clothes_df = pd.read_csv('/content/drive/MyDrive/clothing_class/dataset.csv')"
      ],
      "metadata": {
        "id": "p_CRmJf5H7-r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clothes_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "OAILHdoYJNCe",
        "outputId": "64d6ff89-8a54-492e-bae2-f3df8f9404a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                file_name                                          file_path\n",
              "0   vertical_top_1012.jpg  /content/drive/MyDrive/Capstone/raw_dataset/ve...\n",
              "1   horiz_tshirt_1020.jpg  /content/drive/MyDrive/Capstone/raw_dataset/ho...\n",
              "2  horiz_sweater_1001.jpg  /content/drive/MyDrive/Capstone/raw_dataset/ho...\n",
              "3      horiz_top_1000.jpg  /content/drive/MyDrive/Capstone/raw_dataset/ho...\n",
              "4      horiz_top_1003.jpg  /content/drive/MyDrive/Capstone/raw_dataset/ho..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-cb14f3fb-6826-4d43-9751-2d6129ce40a4\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>file_name</th>\n",
              "      <th>file_path</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>vertical_top_1012.jpg</td>\n",
              "      <td>/content/drive/MyDrive/Capstone/raw_dataset/ve...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>horiz_tshirt_1020.jpg</td>\n",
              "      <td>/content/drive/MyDrive/Capstone/raw_dataset/ho...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>horiz_sweater_1001.jpg</td>\n",
              "      <td>/content/drive/MyDrive/Capstone/raw_dataset/ho...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>horiz_top_1000.jpg</td>\n",
              "      <td>/content/drive/MyDrive/Capstone/raw_dataset/ho...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>horiz_top_1003.jpg</td>\n",
              "      <td>/content/drive/MyDrive/Capstone/raw_dataset/ho...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cb14f3fb-6826-4d43-9751-2d6129ce40a4')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-cb14f3fb-6826-4d43-9751-2d6129ce40a4 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-cb14f3fb-6826-4d43-9751-2d6129ce40a4');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The naming convention of the files, when saved into the raw dataset, included the assigned pattern label, an underscore, and the assigned garment label."
      ],
      "metadata": {
        "id": "gTAjbpw2FbDW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clothes_df['pattern_label'] = [i.split('_')[0] for i in clothes_df['file_name']]\n",
        "clothes_df['garment_label'] = [i.split('_')[1] for i in clothes_df['file_name']]"
      ],
      "metadata": {
        "id": "nZLt1RmJs3qx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fixing typo in naming convention."
      ],
      "metadata": {
        "id": "M77pMHRGKLSM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clothes_df['pattern_label'] = clothes_df['pattern_label'].replace('Copy of animal','animal')"
      ],
      "metadata": {
        "id": "eb5sDDlUJ8PH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "There is an imbalance in the dataset regarding pattern labeling, with solid patterned clothing comprising 56.7% of the images."
      ],
      "metadata": {
        "id": "IxYavElZyekZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clothes_df['pattern_label'].value_counts(normalize=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mzFEgft-jt6k",
        "outputId": "c9b2d1d0-3c2a-45c4-f3bc-f08da53d04bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "solid        0.567527\n",
              "horiz        0.161798\n",
              "polka        0.091426\n",
              "vertical     0.040971\n",
              "checkered    0.039264\n",
              "chevron      0.039264\n",
              "animal       0.036039\n",
              "paisley      0.023710\n",
              "Name: pattern_label, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clothes_df['garment_label'].value_counts(normalize=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EvfSLOc8j08l",
        "outputId": "988a2c90-6603-49b0-f016-2f89c88da041"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dress      0.139226\n",
              "sweater    0.136002\n",
              "coat       0.134484\n",
              "pants      0.129932\n",
              "tshirt     0.116654\n",
              "top        0.107360\n",
              "jacket     0.087253\n",
              "shorts     0.086495\n",
              "skirt      0.062595\n",
              "Name: garment_label, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Resampling for Pattern Modeling"
      ],
      "metadata": {
        "id": "0G__gQobkBGv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "solids = clothes_df[clothes_df[\"pattern_label\"] == \"solid\"]"
      ],
      "metadata": {
        "id": "uy0F6b72R30o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The number of solids in the resampled dataset will be reduced by a factor of 5."
      ],
      "metadata": {
        "id": "uNWI7grjy_8K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "solid_downsample = sklearn.utils.resample(solids,\n",
        "             replace=True,\n",
        "             n_samples=int(len(solids)/5),\n",
        "             random_state=2)\n",
        "\n",
        "non_solid = clothes_df[clothes_df[\"pattern_label\"] != \"solid\"]\n",
        "\n",
        "\n",
        "data_resampled = pd.concat([solid_downsample, non_solid])"
      ],
      "metadata": {
        "id": "dzVFzEW0Nraa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The value count breakdown of the resampled dataset are below. While there remains an imbalance in the dataset, it has been reduced."
      ],
      "metadata": {
        "id": "cGzrbl9dzvn6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_resampled['pattern_label'].value_counts(normalize=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ubcGolBcd0w",
        "outputId": "6b87bdd6-3cc2-4b09-a992-a25100f6d6a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "horiz        0.296386\n",
              "solid        0.207783\n",
              "polka        0.167477\n",
              "vertical     0.075052\n",
              "chevron      0.071925\n",
              "checkered    0.071925\n",
              "animal       0.066018\n",
              "paisley      0.043433\n",
              "Name: pattern_label, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clothes_df['garment_label'].value_counts(normalize=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AH-ASAw0OWDV",
        "outputId": "35e5c6d3-beef-4143-955d-d7dc8eae7aa5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dress      0.139226\n",
              "sweater    0.136002\n",
              "coat       0.134484\n",
              "pants      0.129932\n",
              "tshirt     0.116654\n",
              "top        0.107360\n",
              "jacket     0.087253\n",
              "shorts     0.086495\n",
              "skirt      0.062595\n",
              "Name: garment_label, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The datasets will now be shuffled and saved down."
      ],
      "metadata": {
        "id": "aU6-oMMDNbTA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clothes_df = clothes_df.sample(frac=1,random_state=2)\n",
        "clothes_df.to_csv('/content/drive/MyDrive/clothing_class/dataset.csv',index=False)"
      ],
      "metadata": {
        "id": "cgr4BO0cdQWU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_resampled = data_resampled.sample(frac=1,random_state=2)\n",
        "data_resampled.to_csv('/content/drive/MyDrive/clothing_class/data_resampled.csv',index=False)"
      ],
      "metadata": {
        "id": "5qwn8Vgdf32u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating New Image Datasets"
      ],
      "metadata": {
        "id": "8A-wdmFNb-K8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Four new image datasets are created below, containing a modified version of each image in the dataset. Each uses a different technique of image segmentation, which will then be analyzed for impact on model performance.\n",
        "\n",
        "OpenCV library was used to create the new images, coding guidance provided via the below link.\n",
        "\n",
        "https://machinelearningknowledge.ai/image-segmentation-in-python-opencv/"
      ],
      "metadata": {
        "id": "r4ghldDVcFA5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Image Segmentation - KMeans, 5 Clusters"
      ],
      "metadata": {
        "id": "zfkNbhCgcmc5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for file in data_files:\n",
        "  img = cv2.imread(data_path+'/'+file)\n",
        "  img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
        "  img = cv2.resize(img,(224,224))\n",
        "  twoDimage = img.reshape((-1,3))\n",
        "  twoDimage = np.float32(twoDimage)\n",
        "  criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 100, 0.2)\n",
        "  K = 5\n",
        "  attempts=10\n",
        "  ret,label,center=cv2.kmeans(twoDimage,K,None,criteria,attempts,cv2.KMEANS_PP_CENTERS)\n",
        "  center = np.uint8(center)\n",
        "  res = center[label.flatten()]\n",
        "  result_image = res.reshape((img.shape))\n",
        "  os.chdir('/content/drive/MyDrive/clothing_class/segmented_images/cv2images_kmeans')\n",
        "  cv2.imwrite(file, result_image)"
      ],
      "metadata": {
        "id": "0edK3RGBc4jK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "K-Means segmented images saved to new datafile. 5 clusters were used for the segmentation."
      ],
      "metadata": {
        "id": "TwOYUjIQdLzz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Image Segmentation - KMeans, 3 Clusters"
      ],
      "metadata": {
        "id": "2WbALg-Im4JH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for file in data_files:\n",
        "  img = cv2.imread(data_path+'/'+file)\n",
        "  img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
        "  img = cv2.resize(img,(224,224))\n",
        "  twoDimage = img.reshape((-1,3))\n",
        "  twoDimage = np.float32(twoDimage)\n",
        "  criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 100, 0.2)\n",
        "  K = 3\n",
        "  attempts=10\n",
        "  ret,label,center=cv2.kmeans(twoDimage,K,None,criteria,attempts,cv2.KMEANS_PP_CENTERS)\n",
        "  center = np.uint8(center)\n",
        "  res = center[label.flatten()]\n",
        "  result_image = res.reshape((img.shape))\n",
        "  os.chdir('/content/drive/MyDrive/clothing_class/segmented_images/cv2images_kmeans3')\n",
        "  cv2.imwrite(file, result_image)"
      ],
      "metadata": {
        "id": "cXuoIk_9m3gM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "An addiitonal K-Means image dataset was created, with 3 clusters used for the segmentation."
      ],
      "metadata": {
        "id": "qbgDkXU384A_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Image Segmentation - Contour"
      ],
      "metadata": {
        "id": "BsfSRR0huS1g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for file in data_files:\n",
        "  img = cv2.imread(data_path+'/'+file)\n",
        "  gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
        "  gray = cv2.resize(gray,(224,224))\n",
        "\n",
        "  _,thresh = cv2.threshold(gray, np.mean(gray), 255, cv2.THRESH_BINARY_INV)\n",
        "  edges = cv2.dilate(cv2.Canny(thresh,0,255),None)\n",
        "  contours = sorted(cv2.findContours(edges, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)[-2], key=cv2.contourArea)[-1]\n",
        "  mask = np.zeros(img.shape[0:2], np.uint8)\n",
        "  masked = cv2.drawContours(mask, [contours],-1, 255, -1)\n",
        "  dst = cv2.bitwise_and(img, img, mask=mask)\n",
        "  segmented = cv2.cvtColor(dst, cv2.COLOR_BGR2RGB)\n",
        "  os.chdir('/content/drive/MyDrive/clothing_class/segmented_images/cv2images_contour')\n",
        "  cv2.imwrite(file, segmented)"
      ],
      "metadata": {
        "id": "EQePxzrduSYI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Images created via contouring saved to new datafile."
      ],
      "metadata": {
        "id": "rVaP1u6ZdS8m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Image Segmentation - Thresholding"
      ],
      "metadata": {
        "id": "g63TYjI3yZOi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def filter_image(image, mask):\n",
        "  r = image[:,:,0] * mask\n",
        "  g = image[:,:,1] * mask\n",
        "  b = image[:,:,2] * mask\n",
        "  return np.dstack([r,g,b])\n",
        "\n",
        "for file in data_files:\n",
        "  img = cv2.imread(data_path+'/'+file)\n",
        "  img = cv2.resize(img,(224,224))\n",
        "  img_rgb = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
        "  img_gray = cv2.cvtColor(img_rgb,cv2.COLOR_RGB2GRAY)\n",
        "  img_gray = cv2.resize(img_gray,(224,224))\n",
        "  thresh = threshold_otsu(img_gray)\n",
        "  img_otsu  = img_gray < thresh\n",
        "  filtered = filter_image(img, img_otsu)\n",
        "  os.chdir('/content/drive/MyDrive/clothing_class/segmented_images/cv2images_thresholding')\n",
        "  cv2.imwrite(file, filtered)"
      ],
      "metadata": {
        "id": "C_BefOQeyfvx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Images created via thresholding saved to new datafile."
      ],
      "metadata": {
        "id": "bYNiyf15dbtg"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Data_Preparation.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}